{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker_id</th>\n",
       "      <th>worker_age</th>\n",
       "      <th>worker_lang</th>\n",
       "      <th>worker_fluency</th>\n",
       "      <th>set_name</th>\n",
       "      <th>set_trials</th>\n",
       "      <th>participant_type</th>\n",
       "      <th>platform_type</th>\n",
       "      <th>vision</th>\n",
       "      <th>target_error</th>\n",
       "      <th>...</th>\n",
       "      <th>trial_9_total_fix_points_p_filtered</th>\n",
       "      <th>pre_question_9_name</th>\n",
       "      <th>pre_question_9_time</th>\n",
       "      <th>question_9_name</th>\n",
       "      <th>question_9_time</th>\n",
       "      <th>question_9_answer</th>\n",
       "      <th>question_9_correct_flag</th>\n",
       "      <th>question_9_target_to_fixation_ratio</th>\n",
       "      <th>set_language</th>\n",
       "      <th>fixation_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linkPfXXpFV1cct</td>\n",
       "      <td>20</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>5</td>\n",
       "      <td>mturk_TR_v03</td>\n",
       "      <td>[meco_para_7, a_HarvardUniversity_1, a_Rhine_3...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>271</td>\n",
       "      <td>q_before_a_Teacher_0_qa_4</td>\n",
       "      <td>5869.0</td>\n",
       "      <td>q_after_a_Teacher_0_qa_4</td>\n",
       "      <td>18067.0</td>\n",
       "      <td>fiziksel acı</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>TR</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linkPpaoeaQKkM0</td>\n",
       "      <td>18</td>\n",
       "      <td>Russian</td>\n",
       "      <td>4</td>\n",
       "      <td>mturk_TR_v03</td>\n",
       "      <td>[meco_para_7, a_HarvardUniversity_1, a_Rhine_3...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>131</td>\n",
       "      <td>q_before_a_Teacher_0_qa_4</td>\n",
       "      <td>5902.0</td>\n",
       "      <td>q_after_a_Teacher_0_qa_4</td>\n",
       "      <td>70096.0</td>\n",
       "      <td>fiziksel acıya</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007634</td>\n",
       "      <td>TR</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A4W9APAHFWVLO</td>\n",
       "      <td>41</td>\n",
       "      <td>English</td>\n",
       "      <td>5</td>\n",
       "      <td>mturk_EN_v13</td>\n",
       "      <td>[meco_para_12, a_DoctorWho_4, a_VictoriaAustra...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>q_before_a_FresnoCalifornia_0_qa_0</td>\n",
       "      <td>1656.0</td>\n",
       "      <td>q_after_a_FresnoCalifornia_0_qa_0</td>\n",
       "      <td>3148.0</td>\n",
       "      <td>southwest Fresno</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>EN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linkPnEwgBwkH4O</td>\n",
       "      <td>20</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>5</td>\n",
       "      <td>mturk_TR_v03</td>\n",
       "      <td>[meco_para_7, a_HarvardUniversity_1, a_Rhine_3...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>q_before_a_Teacher_0_qa_4</td>\n",
       "      <td>10271.0</td>\n",
       "      <td>q_after_a_Teacher_0_qa_4</td>\n",
       "      <td>19051.0</td>\n",
       "      <td>fiziksel acıya</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>TR</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AYY0UC6KCN9RW</td>\n",
       "      <td>27</td>\n",
       "      <td>English</td>\n",
       "      <td>5</td>\n",
       "      <td>mturk_EN_v02</td>\n",
       "      <td>[meco_para_3, a_Computationalcomplexitytheory_...</td>\n",
       "      <td>mturk</td>\n",
       "      <td>mturk</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>q_before_a_DoctorWho_3_qa_0</td>\n",
       "      <td>12534.0</td>\n",
       "      <td>q_after_a_DoctorWho_3_qa_0</td>\n",
       "      <td>10072.0</td>\n",
       "      <td>DUDLEY SIMPSON</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.165049</td>\n",
       "      <td>EN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         worker_id  worker_age worker_lang  worker_fluency      set_name  \\\n",
       "0  linkPfXXpFV1cct          20     Turkish               5  mturk_TR_v03   \n",
       "1  linkPpaoeaQKkM0          18     Russian               4  mturk_TR_v03   \n",
       "2    A4W9APAHFWVLO          41     English               5  mturk_EN_v13   \n",
       "3  linkPnEwgBwkH4O          20     Turkish               5  mturk_TR_v03   \n",
       "4    AYY0UC6KCN9RW          27     English               5  mturk_EN_v02   \n",
       "\n",
       "                                          set_trials participant_type  \\\n",
       "0  [meco_para_7, a_HarvardUniversity_1, a_Rhine_3...             None   \n",
       "1  [meco_para_7, a_HarvardUniversity_1, a_Rhine_3...             None   \n",
       "2  [meco_para_12, a_DoctorWho_4, a_VictoriaAustra...             None   \n",
       "3  [meco_para_7, a_HarvardUniversity_1, a_Rhine_3...             None   \n",
       "4  [meco_para_3, a_Computationalcomplexitytheory_...            mturk   \n",
       "\n",
       "  platform_type vision  target_error  ...  \\\n",
       "0          None   None         False  ...   \n",
       "1          None   None         False  ...   \n",
       "2          None   None         False  ...   \n",
       "3          None   None         False  ...   \n",
       "4         mturk   None         False  ...   \n",
       "\n",
       "   trial_9_total_fix_points_p_filtered                 pre_question_9_name  \\\n",
       "0                                  271           q_before_a_Teacher_0_qa_4   \n",
       "1                                  131           q_before_a_Teacher_0_qa_4   \n",
       "2                                   26  q_before_a_FresnoCalifornia_0_qa_0   \n",
       "3                                   27           q_before_a_Teacher_0_qa_4   \n",
       "4                                  103         q_before_a_DoctorWho_3_qa_0   \n",
       "\n",
       "  pre_question_9_time                    question_9_name  question_9_time  \\\n",
       "0              5869.0           q_after_a_Teacher_0_qa_4          18067.0   \n",
       "1              5902.0           q_after_a_Teacher_0_qa_4          70096.0   \n",
       "2              1656.0  q_after_a_FresnoCalifornia_0_qa_0           3148.0   \n",
       "3             10271.0           q_after_a_Teacher_0_qa_4          19051.0   \n",
       "4             12534.0         q_after_a_DoctorWho_3_qa_0          10072.0   \n",
       "\n",
       "   question_9_answer  question_9_correct_flag  \\\n",
       "0       fiziksel acı                      1.0   \n",
       "1    fiziksel acıya                       1.0   \n",
       "2   southwest Fresno                      1.0   \n",
       "3     fiziksel acıya                      1.0   \n",
       "4     DUDLEY SIMPSON                      1.0   \n",
       "\n",
       "   question_9_target_to_fixation_ratio  set_language  fixation_error  \n",
       "0                             0.007380            TR           False  \n",
       "1                             0.007634            TR           False  \n",
       "2                             0.000000            EN           False  \n",
       "3                             0.000000            TR           False  \n",
       "4                             0.165049            EN           False  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRE_PROCESS_DATA_FOLDER = \"pre_processed_data\"\n",
    "TEXT_DATA_FOLDER = os.path.join(\"experiment_data\", \"set_texts\")\n",
    "FIXATION_DATA_FOLDER = os.path.join(\"pre_processed_data\",\"fixation_data_per_part\")\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for file in os.listdir(PRE_PROCESS_DATA_FOLDER):\n",
    "    if \".json\" not in file:\n",
    "        continue\n",
    "    with open(os.path.join(PRE_PROCESS_DATA_FOLDER, file), \"r\") as f:\n",
    "        load_data = json.load(f)\n",
    "    data_list.append(pd.Series(list(load_data.values()), index=load_data.keys()))\n",
    "data = pd.DataFrame(data_list)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For condition (filter_mturks), 37.36% has been filtered. (226 out of 605)\n",
      "For condition (filter_sets), 43.27% has been filtered. (164 out of 379)\n",
      "For condition (Approved), 18.60% has been filtered. (40 out of 215)\n",
      "For condition (Fix_Error, Target_Error), 2.86% has been filtered. (5 out of 175)\n",
      "For condition (Sample Rate), 8.24% has been filtered. (14 out of 170)\n",
      "For condition (acc_thresh), 1.28% has been filtered. (2 out of 156)\n",
      "For condition (screen_above_1280_720), 0.00% has been filtered. (0 out of 154)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filters to apply:\n",
    "approved_only = (data.approved_flag > 0).to_numpy() \n",
    "no_fixation_error = (data.fixation_error == False).to_numpy()\n",
    "no_target_error = (data.target_error == False).to_numpy()\n",
    "sample_higher_10 = (data.webgazer_sample_rate > 10).to_numpy()\n",
    "acc_higher = (data.avg_roi_last_val > 0).to_numpy()\n",
    "filter_mturks = np.array([False if \"link\" in worker_id else True for worker_id in data[\"worker_id\"]])\n",
    "filter_sets = np.array([True if set_lang in [\"EN\"] else False for set_lang in data[\"set_language\"]])\n",
    "\n",
    "screen_x_above_1280 = (data.screen_x > 1110).to_numpy() # Some tolerance\n",
    "screen_y_above_720 = (data.screen_y > 615).to_numpy() # Some Tolerance\n",
    "screen_above_1280_720 = screen_x_above_1280 & screen_y_above_720\n",
    "\n",
    "dict_filter = {\n",
    "    \"filter_mturks\" : filter_mturks,\n",
    "    \"filter_sets\" : filter_sets,\n",
    "    \"Approved\":approved_only,\n",
    "    \"Fix_Error, Target_Error\": no_fixation_error & no_target_error,\n",
    "    \"Sample Rate\": sample_higher_10,\n",
    "    \"acc_thresh\": acc_higher,\n",
    "    \"screen_above_1280_720\": screen_above_1280_720,\n",
    "}\n",
    "\n",
    "n_total = len(data)\n",
    "current_filter = np.ones(len(data),dtype=bool)\n",
    "for condition, f in dict_filter.items():\n",
    "    n_data_filtered = len(data.iloc[~f & current_filter])\n",
    "    per_cent = n_data_filtered/n_total * 100\n",
    "    print(f\"For condition ({condition}), {per_cent:.2f}% has been filtered. ({n_data_filtered} out of {n_total})\")\n",
    "    current_filter = current_filter & f\n",
    "    n_total = len(data.iloc[current_filter])\n",
    "\n",
    "mask = filter_mturks & approved_only & no_fixation_error & no_target_error & sample_higher_10 & screen_above_1280_720 & acc_higher & filter_sets\n",
    "data_filtered = data[mask].copy()\n",
    "len(data_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target data structure:  \n",
    "An array of JSON object:  \n",
    "[  \n",
    "    {  \n",
    "        \"worker_id\": id,  \n",
    "        \"set_name\": name,  \n",
    "        \"text_id\": id,  \n",
    "        \"text\": text,  \n",
    "        \"question_id\": id,  \n",
    "        \"question\": question    \n",
    "    }  \n",
    "]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154\n",
      "5\n",
      "154\n",
      "6\n",
      "154\n",
      "7\n",
      "154\n",
      "8\n",
      "154\n",
      "9\n",
      "770\n"
     ]
    }
   ],
   "source": [
    "# Only need IS \n",
    "target_features_list = []\n",
    "for i in range (5, 10):\n",
    "    target_features = data_filtered[['worker_id', 'set_name', f'trial_{i}_condition', f'trial_{i}_name', f'question_{i}_name']]\n",
    "    print(len(target_features))\n",
    "    for key in range(len(target_features)):\n",
    "        # Convert Python to JSON  \n",
    "        # print()\n",
    "        # json_object = json.dumps(target_features.iloc[key].to_dict(), indent = 4) \n",
    "        target_dict = target_features.iloc[key].to_dict()\n",
    "        temp_dict = {}\n",
    "        for key in target_dict:\n",
    "            if 'trial_' in key and '_name' in key:\n",
    "                temp_dict['text_name'] = target_dict[key]\n",
    "            if 'question_' in key and '_name' in key:\n",
    "                temp_dict['question_name'] = target_dict[key]\n",
    "        target_dict.update(temp_dict)\n",
    "        target_features_list.append(target_dict)\n",
    "    print(i)\n",
    "print(len(target_features_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stimulus</th>\n",
       "      <th>trial_name</th>\n",
       "      <th>task_type</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In competitive sports, doping is the use of ba...</td>\n",
       "      <td>meco_para_3</td>\n",
       "      <td>NR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can doping have adverse health effects?</td>\n",
       "      <td>meco_para_3_qa_0</td>\n",
       "      <td>NR</td>\n",
       "      <td>True</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When considering computational problems, a pro...</td>\n",
       "      <td>a_Computationalcomplexitytheory_1</td>\n",
       "      <td>NR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the name of the alphabet is most commo...</td>\n",
       "      <td>a_Computationalcomplexitytheory_1_qa_1</td>\n",
       "      <td>NR</td>\n",
       "      <td>binary</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Many known complexity classes are suspected to...</td>\n",
       "      <td>a_Computationalcomplexitytheory_4</td>\n",
       "      <td>NR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            stimulus  \\\n",
       "0  In competitive sports, doping is the use of ba...   \n",
       "1            Can doping have adverse health effects?   \n",
       "2  When considering computational problems, a pro...   \n",
       "3  What is the name of the alphabet is most commo...   \n",
       "4  Many known complexity classes are suspected to...   \n",
       "\n",
       "                               trial_name task_type correct_answer lang  \n",
       "0                             meco_para_3        NR            NaN   EN  \n",
       "1                        meco_para_3_qa_0        NR           True   EN  \n",
       "2       a_Computationalcomplexitytheory_1        NR            NaN   EN  \n",
       "3  a_Computationalcomplexitytheory_1_qa_1        NR         binary   EN  \n",
       "4       a_Computationalcomplexitytheory_4        NR            NaN   EN  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = []\n",
    "\n",
    "for file in os.listdir(TEXT_DATA_FOLDER):\n",
    "    if \"EN_\" not in file:\n",
    "        continue\n",
    "    temp_data = pd.read_csv(os.path.join(TEXT_DATA_FOLDER, file), index_col=0)\n",
    "    data_list.append(temp_data)\n",
    "\n",
    "print(len(data_list))\n",
    "text_data = pd.concat(data_list, ignore_index=True)\n",
    "print(len(text_data))\n",
    "text_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target data structure:  \n",
    "An array of JSON object:  \n",
    "[  \n",
    "    {  \n",
    "        \"worker_id\": id,  \n",
    "        \"set_name\": name,  \n",
    "        \"text_id\": id,  \n",
    "        \"text\": text,  \n",
    "        \"question_id\": id,  \n",
    "        \"question\": question    \n",
    "    }  \n",
    "]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'worker_id': 'A4W9APAHFWVLO', 'set_name': 'mturk_EN_v13', 'trial_5_condition': 'is', 'trial_5_name': 'a_Kenya_1', 'question_5_name': 'q_after_a_Kenya_1_qa_0', 'text_name': 'a_Kenya_1', 'question_name': 'q_after_a_Kenya_1_qa_0'}\n"
     ]
    }
   ],
   "source": [
    "print(target_features_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint as pp\n",
    "for item in target_features_list:\n",
    "    for i in range(len(text_data)):\n",
    "        if item[\"text_name\"] == text_data.iloc[i]['trial_name']:\n",
    "            item['text'] = text_data.iloc[i]['stimulus']\n",
    "        if item[\"question_name\"] == text_data.iloc[i]['trial_name']:\n",
    "            item['question'] = text_data.iloc[i]['stimulus']\n",
    "    # pp.pprint(item)\n",
    "        # break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify\n",
    "for item in target_features_list:\n",
    "    if len(item) != 9:\n",
    "        pp.pprint(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save into files\n",
    "with open(\"target_experiments_IS_EN.json\", \"w\") as outfile:\n",
    "    json.dump(target_features_list, outfile, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
